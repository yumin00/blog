---
title: "DAU 파이프라인 설계"
date: 2024-06-18T21:10:45+09:00
draft: false
categories :
- DataEngineering
---

이 글에서는 데이터 사이언티스트에게 제공하기 위해서 **DAU를 추출하는 파이프라인**을 직접 설계해보고자 한다.

# 파이프라인 설계
## 데이터 수집
먼저, DAU를 추출하기 위해서는 사용자의 APP 사용 여부를 알아야 한다. APP으로부터 DAU를 알아오는 방법에 대해 생각해 보자.

APP을 진입하면 무조건 특정 API를 호출한다고 가정한다면, 해당 API를 호출 여부를 통해 DAU를 추출할 수 있다.
먼저 백엔드 개발자로부터 해당 API가 호출되면 해당 로그를 전달받아야 한다. 이때 Kafka 또는 Google Pub/Sub과 같은 메시지 큐를 통해 전달받을 수 있다.

Google Pub/Sub은 메모리에 저장하기 때문에 안정성은 낮지만 속도가 빠르다. Kafka는 파일 형태로 디스크에 저장하기 때문에 안정성은 높지만 속도가 Google Pub/Sub보다는 느릴 수 있다.
해당 파이프라인에서는 속도보다는 안정성이 중요하기 때문에 Kafka를 선택하고자 한다.

전달받을 데이터의 스키마는 다음과 같다.
```json
{
  "userId": 0,
  "date": "YYYY-MM-DD"
}
```

Kafka를 통해 전달받은 데이터는 변환하기 전 먼저 DataLake에 저장하고자 한다.
해당 데이터는 DAU뿐만 아니라 MAU나 유저의 하루 APP 실행 수 등 여러 데이터에도 활용될 수 있을 것 같기 때문에 DataLake에 저장하여 필요에 따라 다른 파이프라인에도 같이 사용하고자 한다.

Kafka와 Connector를 사용하여 BigQuery에 바로 적재하고자 한다.

## 데이터 처리
전날 APP에 접속한 사용자의 수를 수집하기 위해, 00시마다 BigQuery로부터 데이터를 추출하여 유저의 중복 데이터를 삭제하고 데이터 사이언티스트에게 해당 데이터를 전달하는 Airflow DAG를 실행시킬 것이다.

BigQuery에서 데이터를 추출할 때 중요한 것은 쿼리 성능을 최적화하는 것이다. 해당 BigQuery 테이블에는 매일 매일 사용자의 로그가 담겨있을 것이다.
그렇기 때문에 파티셔닝을 사용하여 불필요한 데이터 스캔을 방지하고 쿼리 성능을 향상시키고 비용을 절감하고자 한다. 테이블은 날짜를 기준으로 분할할 것이다.

이때, DAU를 산출하고자 하는 날짜의 로그를 모두 가져와 중복되는 userId를 제거해야 한다. 데이터 처리 속도를 빠르게 하기 위해 Spark를 사용할 것이고 이는 Airflow DAG로 실행시킬 것이다.

## 데이터 저장
Airflow DAG를 사용하여 DAU를 산출한 뒤, 이를 데이터 사이언티스트에게 전달해야 한다. 전달하는 방식은 데이터 사이언티스트의 요청대로 전달해 줄 것이다. (ex. DB, xlsx)

![image](https://github.com/yumin00/blog/assets/130362583/a6f8d8d5-9b1e-4103-bf62-b4655057bd2d)