---
title: "주니어 백엔드 엔지니어의 2024 회고"
date: 2024-03-25T19:49:22+09:00
draft: true
categories :
  - Retrospective
---

올해 분명 공부도 많이 하고 컨퍼런스도 다녀오고 이것저것 한 것 같은데 막상 회고를 작성하려고 하니 떠오르는 것이 없다.
그래서 공부한 내용을 기록한 깃헙과 컨퍼런스를 다녀온 사진들, 읽었던 책들, 내가 고민했던 내용들은 다시 하나하나씩 차근차근 복기해보면서 회고를 작성해본다!

### 1월
1월에는 주로 사이드 프로젝트를 하며 시간을 많이 보냈다. 회사에서 업무를 진행하는 것과 별개로 더 많은 것을 공부해보고자 시작했다.

뮤지컬 덕후 iOS 개발자와 함께 뮤지컬 티켓팅 달력 서비스를 제공하는 앱을 만드는 것이 목표였다.

앱 개발자에게 Swagger로 API 문서를 제공하기 위해서 [Doker](https://yumin.dev/p/docker%EC%99%80-docker-compose/)와 [Swagger](https://yumin.dev/p/swaggeropenapi%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90/)에 대해서 자세히 공부해볼 수 있었다.

### 2월
2월은 사이드 프로젝트 조금하고 다른 공부는 거의 하지 않았다.. 왜 이렇게 스레기처럼 살았지? 싶었는데 생각해보니(조금 핑계를 대보자면) 이때 연봉 협상 시즌이었고, 내가 어떤 개발을 하고 싶은 사람인지에 대해 고민하느라 공부를 안 했다...

이때 내가 뭘하고 싶은지 고민을 하면서 사내에서 ETL 파이프라인을 만들던 업무가 가장 재미있었기 때문에 내가 데이터 엔지니어링에 관심이 있는 사람이라는 것을 알게 되었고, 앞으로 데이터 엔지니어가 되기 위해서는 어떤 공부를 하면 좋을지 계획을 세웠다.

### 3월
그래서 3월부터는 데이터 엔지니어와 관련된 공부를 하기 시작했다. 사내에서 파이프라인 개발이 필요했는데 이때 [Airflow](https://yumin.dev/p/airflow-%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90/)에 대해 공부하고 관련하여 PoC도 같이 진행했었다.

Airflow에 대해 공부하며 나처럼 Airflow를 처음 사용해보는 사람도 쉽게 시작해볼 수 있도록 [튜토리얼 블로그 글](https://yumin.dev/p/airflow-%ED%8A%9C%ED%86%A0%EB%A6%AC%EC%96%BC/)도 작성했었다.

그리고 CS의 기반도 탄탄하게 하기 위해서 예전에 읽었던 `혼자 공부하는 컴퓨터 구조+운영체제`을 다시 읽어보며 복기하는 시간도 가졌었다.

3월에는 공부를 좀 열심히 했던 것 같은데(2월에 목표를 제대로 세워서 그거를 발판 삼아서 열심히 한 것 같다) 사내에서 카프카를 도입하게 되어서 이 프로젝트를 맡게 되어 카프카에 대해서도 공부를 열심히 했었다.

하지만 카프카는 돌아보면 조금 얕게 공부했던 것 같다. 적용하는 것을 우선해서 카프카 자체에 대한 딥한 공부를 하지 않았던 게 많이 아쉽다. 내년에는 카프카 관련해서 인강도 같이 들으면서 더 깊게 공부하는 것이 목표다!!!

### 4월
4월에도 데이터 엔지니어에 대한 목표를 기반으로 DB와 관련된 공부를 집중적으로 진행했다. 그리고 네트워크와 관련한 기본기도 놓지 않기 위해 작년에 읽으며 공부했던 `그림으로 쉽게 이해하는 웹/HTTP/네트워크` 책을 다시 읽었다.

### 5월
5월에는 데이터 엔지니어링 관련된 개념들을 공부하면서 응용 사례에 대해 공부했다. 가장 기억에 남는 것은 [CQRS](https://yumin.dev/p/cqrs-%ED%8C%A8%ED%84%B4%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90/)에 대해 공부한 것인데, 개념만 공부하는 것이 아니라 실제 서비스에 어떤 식으로 적용할 수 있을지에 고민해볼 수 있는 기회였다.

이때는 사이드 프로젝트 배포를 위해 처음으로 AWS를 공부했다. 사내에서는 GCP를 위주로 사용했지만 이번에는 AWS를 사용하면서 E2C에 대해 공부해볼 수 있었다.

그런데 당시에 공부하고 이후에 복습하지 않아서 지금은 AWS에 대해 잘 알지 못한다.. 현재 진행하고 있는 사이드 프로젝트도 AWS로 배포할 것 같은데 다시 공부를 해서 완전히 내것으로 만들어야할 것 같다!

### 6월
6월에는 주로 [하둡](https://yumin.dev/p/hadoop%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90/)과 [레디스](https://yumin.dev/p/redis%EC%97%90-%EB%8C%80%ED%95%B4-%EC%95%8C%EC%95%84%EB%B3%B4%EC%9E%90/)에 대해 공부해보았다. 레디스는 사용해본 적이 있기 때문에 좀 더 수월하게 공부할 수 있었는데 하둡은 처음 접해봐서 이해하는데 애를 먹었다.

그리고 DAU 아키텍처를 직접 설계해보면서 지금까지 공부한 내용을 바탕으로 데이터를 안정적으로 흐르게 할 수 있는 파이프라인 아키텍처를 생각해보기도 했다! 나는 뭔가 아키텍처를 설계하거나 공부한 내용들을 직접 적용해보는 데에서 재미를 느끼는 것 같다.. 하지만 그러기 위해서는 적용할 도구들에 대해 깊게 공부하는 것이 중요하다는 것을 잊으면 안된다!!!

6월부터는 사이드 프로젝트에 대해 중단하게 되었다. 뮤지컬 데이터를 가져오는 과정에서 너무 어려움을 느꼈고 의지도 많이 꺾이면서 중단했다.. 올해 12월부터 다시 프로젝트 인원을 꾸려서 진행하고 있는데, 이번에는 절대 포기하지 않고 좋은 서비스를 만들 수 있도록 노력할 것이다.

### 7월
3월에 사내에서 카프카 프로젝트를 진행하면서 아쉬웠던 것을 보완하기 위해서 패스트캠퍼스의 카프카 인강을 들으며 배운 내용들은 블로그로 열심히 작성했다.

정말 아쉽게도 사내에서 인프라를 GCP로 옮기면서 카프카를 사용하지 않게 되었는데, 그래도 스스로 꾸준히 공부하고자 카프카를 인강으로 듣기 시작했다.

### 8월
8월에도 카프카 인강을 주로 들으면서 스파크 강의도 같이 듣기 시작했다. 데이터 엔지니어 공고를 보면 카프카, 스파크, 하둡은 기본 역량으로 원하는 것을 보고 이 역량을 갖추기 위해 공부하기 시작했다.

### 9월
9월에 빅 이베트는 토스 컨퍼런스였다. 예전에 Go 컨퍼런스도 다녀왔었다. 이때는 개발을 막 시작했을 때라서 가서 전부 다 이해하고 오는 것은 정말 어려워서 아쉬운 점으로 남아있었다.

토스 컨퍼런스에서는 아주 많은 데이터를 어떤식으로 관리하고, 안전한 서비스 운영을 위해서 백엔드를 어떤 아키텍처를 가지고 개발하고 있는지에 대해 배울 수 있었다.

특히 보상 서비스 아키텍처에 대한 강연은 많은 것을 배울 수 있었다. 돈이 움직이는 서비스는 더욱 단단한 서비스와 에러 핸들링이 중요한데, 카프카를 사용하면서 에러 핸들링을 어떤식으로 진행하는지 배울 수 있었다.

그리고 9월에는 테라폼에 대해서 많은 공부를 진행했다. 사내에서 [Cloud Functions를 배포](https://yumin.dev/p/cloud-functions-%EB%B0%B0%ED%8F%AC-%EC%9E%90%EB%8F%99%ED%99%94%ED%95%98%EA%B8%B0/)할 수 있도록 테라폼을 구성하는 것이 목표였는데 이를 위해 테라폼에 대해서 아주 열심히 공부했고, 이제는 나름 테라폼 Docs를 보면서 잘 작성하고 배포할 수 있는 사람이 된 것 같아서 뿌듯하다. 

### 10월
10월에는 카카오 모빌리티에서 MlOps 채용 공고가 있어서 지원했었다. 서류는 합격하여 코딩 테스트를 위해 거의 모든 시간을 코테 공부를 진행했다.

이때 내가 코테를 너무 못해서(ㅜㅜ) 공부를 열심히 했지만 아쉽게도 떨어졌다... 앞으로 어떤 공고에서 어떤 코테가 기다릴지 모르기 때문에 매주 두 문제씩 풀면서 감을 익히는 것이 목표이다.

10월에는 데이터 엔지니어로 직무 전환을 위해 이력서와 포트폴리오를 완성했었다. 내가 진행한 프로젝트는 꾸준히 업데이트해야한다는 것을 깨달았다..

### 11월
11월에는 네이버 컨퍼런스를 다녀왔다. 네이버 컨퍼런스는 주로 AI, 머신러닝 위주의 내용이 많았다. 아직 내가 머신러닝 쪽에 대해서는 제대로 공부해 본 적이 없어서 모든 강연을 이해하는 것은 어려웠다. 좀 더 지식을 쌓은 다음 들었다면 유익했을 것 같은데, 아쉬움이 남는다..

그리고 데이터 엔지니어의 직무 전환에 실패하고 백엔드로서의 기반을 더 다지는 것을 목표로 이력서와 포트폴리오를 정리하고 다시 이직 준비를 진행했다.

### 12월
백엔드로의 이직에서도 쓴 맛을 맛보고 어떤 공부를 하고, 어떤 식으로 준비해야 내가 원하는 곳에 갈 수 있을지 많은 고민을 했다.

먼저 기본기를 지속적으로 다지고, 내가 가고싶은 기업이 사용하는 언어에 대해 깊게 공부하며 이를 적용해보는 것을 먼저 단기 목표로 설정했다.

그래서 지금은 기본기를 다지고, 코테 공부를 먼저 위주로 진행하고 있다!

----
올해 참 많은 일이 있었다.. 내가 무슨 개발자가 되고 싶은지에 대해서도 고민하고, 내가 이직하기 위해서는 어떤 공부를 해야하고 어떤 목표를 세워야 할지에 대해 많은 고민을 했다. 너무 스트레스도 많이 받아서 자주 울기도 하고 올해가 가장 힘들었던 것 같다.

올해의 아쉬운 점은 큰 목표를 세우지 않고 너무 당장의 일을 해결하기 위한 것들만 진행했다. 그래서 막상 회고를 하고자 하니 정해놨던 목표가 없으니 이를 평가하고 돌아볼 수 있는 기회가 없어서 내가 어떤 공부를 했는지 나열밖에 하지 못했다.

하지만 내년에는 목표를 세우고 이를 이루기 위해 어떤 것들을 할 것인지 세부적으로 세우려고 한다. 그래서 내년 회고에는 내 목표를 돌아보면서 내가 한 것들을 적어보고 리뷰해볼 수 있으면 더 좋을 것 같다.

그걸 이제야 깨달은 것이 너무 늦었다고 생각하지만, 늦었다고 생각할 때가 가장 빠른 것이라고 위안을 삼고 앞으로 더 열심히 해보고자 한다!!

---
## 2025년 계획
2025년 목표: 백엔드 엔지니어로 이직

### 주기적으로
- 코테 공부 (자바로 풀기 / 이직할 때까지 / 일주일에 두 문제)
- 기본기 공부 
    - 컴퓨터구조/OS, 네트워크, SQL 책 한 번씩 완독 (3개월)
    - JAVA 공부
    - h
- 이력서/포트폴리오 업데이트
- 채용 공고 자주 보기

### 상반기
- java 기본기 습득 (12/29 ~ 1/5)
- java 응용편?
- spring 공부

- 클라우드 (회사로 넘길 수 있으면 좋겠음.)
  - GCP 환경에 대한 Overview + 네트워크의 흐름 + 배포 상태(ex. cloud run은 어떻게 배포를 하고 / atalntis 배포 과정에 대한 정확한 이해)
  - 컨테이너 (ex. 컨테이너에서 네트워크를 어떻게 연결/사용하는가?)

- JVM
  - 강의 시청 (JVM에서 깊에 다루지 않으면 스스로 공부해야 함.)
  - JVM을 통한 트러블 슈팅 (JVM을 들여다볼 줄 알아야함. JVM에서 무엇이 문제인지 알 수 있어야함.)

- 테스트 코드
  - TDD에 대해 공부하며
  - 자바에서의 유닛 테스트

- 사이드 프로젝트를 하면서 NoSQL 스터디 (dynamo db? - 문서 공부)


만약 시간에 남는다면 아래 스터디도 진행 못하면 하반기로 넘기기

- 분산처리 시스템에 대한 공부 (클라우드 네이티브하게 접근해 보면 좋을 것 같음.)
  - 분산 transaction (개념원리 + 코드구현)
  - 분산 lock (개념원리 + 코드구현)
  - 동시성 (개념원리 + 코드구현)
---

### 하반기
- Kubernetes
  - 마이크로 서비스 아키텍처 이해
  - 대용량 트래픽 처리를 위한 애플리케이션 아키텍처 구성
  - 고가용성의 확장 가능한 시스템을 설계하고 운영
  - Kafka
  - ElasticSearch
  - SQL, NoSQL 같이 사용하는 CQRS 사례를 공부해보고 직접 구현해보는 경험
- 대규모의 실시간 트래픽을 처리하는 시스템 개발 경험 (?)
- 장애를 경험하고 문제를 해결해보신 경험 (?)


level up
- OSS 분석
- 클라우드를 격리시키는 방법 (가상환경을 만들면서 격리시키는 방법 => OS + 네트워크)
- PosgreSQL 책
